{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SeGz4AMGrMLw13Mn3jT4EofJfAiqIYZL",
      "authorship_tag": "ABX9TyMylzHx8VyF9P9hfGrX44JO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IP-Michael/Project-FOML/blob/main/cs24mtech12010_assign1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1LJh9bQuSuM",
        "outputId": "535ef29b-802c-4531-bbfc-752a44ee0792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.1.4)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "pip install ucimlrepo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nRW17yODuL7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Define the Decision Tree Classifier\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.features = X.columns\n",
        "        self.tree = self._build_tree(X, y, depth=0)\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        if len(np.unique(y)) == 1:\n",
        "            return y.iloc[0]\n",
        "\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return y.mode()[0]\n",
        "\n",
        "        best_feature, best_threshold = self._best_split(X, y)\n",
        "\n",
        "        if best_feature is None:\n",
        "            return y.mode()[0]\n",
        "\n",
        "        left_indices = X[best_feature] <= best_threshold\n",
        "        right_indices = X[best_feature] > best_threshold\n",
        "\n",
        "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return (best_feature, best_threshold, left_tree, right_tree)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        best_gain = 0\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "\n",
        "        for feature in X.columns:\n",
        "            thresholds = np.unique(X[feature])\n",
        "            for threshold in thresholds:\n",
        "                gain = self._information_gain(X, y, feature, threshold)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _information_gain(self, X, y, feature, threshold):\n",
        "        parent_entropy = self._entropy(y)\n",
        "\n",
        "        left_indices = X[feature] <= threshold\n",
        "        right_indices = X[feature] > threshold\n",
        "\n",
        "        if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
        "            return 0\n",
        "\n",
        "\n",
        "        left_entropy = self._entropy(y[left_indices])\n",
        "        right_entropy = self._entropy(y[right_indices])\n",
        "\n",
        "        left_weight = len(y[left_indices]) / len(y)\n",
        "        right_weight = len(y[right_indices]) / len(y)\n",
        "\n",
        "        child_entropy = left_weight * left_entropy + right_weight * right_entropy\n",
        "\n",
        "        return parent_entropy - child_entropy\n",
        "\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        proportions = np.bincount(y) / len(y)          #getting proportion of 0's and 1's\n",
        "        return -np.sum(proportions * np.log2(proportions + 1e-10))  # Small constant to avoid log(0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return X.apply(lambda row: self._predict_node(row, self.tree), axis=1)\n",
        "\n",
        "    def _predict_node(self, row, node):\n",
        "        if not isinstance(node, tuple):\n",
        "            return node\n",
        "\n",
        "        feature, threshold, left_tree, right_tree = node\n",
        "        if row[feature] <= threshold:\n",
        "            return self._predict_node(row, left_tree)\n",
        "        else:\n",
        "            return self._predict_node(row, right_tree)\n",
        "\n",
        "# Define the cross-validation function\n",
        "def cross_validate(X, y, k=10):\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) #For Stratified Sampling\n",
        "    accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Initialize and train the decision tree\n",
        "        tree = DecisionTree(max_depth=6)\n",
        "        tree.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = tree.predict(X_test)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(accuracy)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "# Fetch the data\n",
        "wine_quality = fetch_ucirepo(id=186)\n",
        "X = wine_quality.data.features\n",
        "y = wine_quality.data.targets\n",
        "\n",
        "# Convert 'quality' to binary classification: 0 for < 7, 1 for >= 7\n",
        "y = (y['quality'] >= 7).astype(int)\n",
        "\n",
        "# Perform cross-validation\n",
        "average_accuracy = cross_validate(X, y, k=10)\n",
        "print(f\"Average Accuracy (10-fold CV): {average_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lir4DvHYPXYy",
        "outputId": "06d3e2b3-8a75-4629-ac0c-082d171f1655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8061538461538461\n",
            "0.8123076923076923\n",
            "0.8246153846153846\n",
            "0.82\n",
            "0.8353846153846154\n",
            "0.8430769230769231\n",
            "0.8246153846153846\n",
            "0.8397534668721109\n",
            "0.8489984591679507\n",
            "0.8412942989214176\n",
            "Average Accuracy (10-fold CV): 0.830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Define the Decision Tree Classifier with multi-way splits\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.features = X.columns\n",
        "        self.tree = self._build_tree(X, y, depth=0)\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "      if len(np.unique(y)) == 1:\n",
        "        return y.iloc[0]\n",
        "\n",
        "      if self.max_depth is not None and depth >= self.max_depth:\n",
        "        return y.mode().iloc[0] if not y.mode().empty else None\n",
        "\n",
        "      # if len(y) < 2:  # Early stopping for small nodes\n",
        "      #   return y.mode().iloc[0] if not y.mode().empty else None\n",
        "\n",
        "      best_feature, best_thresholds = self._best_split(X, y)\n",
        "\n",
        "      if best_feature is None:\n",
        "        return y.mode().iloc[0] if not y.mode().empty else None\n",
        "\n",
        "      sub_trees = {}\n",
        "      for i in range(len(best_thresholds) + 1):\n",
        "        if i == 0:\n",
        "            indices = X[best_feature] <= best_thresholds[i]\n",
        "        elif i == len(best_thresholds):\n",
        "            indices = X[best_feature] > best_thresholds[i - 1]\n",
        "        else:\n",
        "            indices = (X[best_feature] > best_thresholds[i - 1]) & (X[best_feature] <= best_thresholds[i])\n",
        "        if len(y[indices]) == 0:\n",
        "          sub_trees[i] = y.mode().iloc[0] if not y.mode().empty else None\n",
        "        else:\n",
        "          sub_trees[i] = self._build_tree(X[indices], y[indices], depth + 1)\n",
        "\n",
        "      return (best_feature, best_thresholds, sub_trees)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        best_gain = 0\n",
        "        best_feature = None\n",
        "        best_thresholds = None\n",
        "\n",
        "        for feature in X.columns:\n",
        "            thresholds = np.unique(X[feature])\n",
        "            if len(thresholds) == 0:\n",
        "                continue\n",
        "            potential_splits = np.percentile(thresholds, [25, 50, 75])  # Example: multiway split at quartiles\n",
        "            gain = self._multiway_gini_gain(X, y, feature, potential_splits)\n",
        "\n",
        "            if gain > best_gain:\n",
        "                best_gain = gain\n",
        "                best_feature = feature\n",
        "                best_thresholds = potential_splits\n",
        "\n",
        "        return best_feature, best_thresholds\n",
        "\n",
        "    def _multiway_gini_gain(self, X, y, feature, thresholds):\n",
        "        parent_gini = self._gini(y)\n",
        "        total_weighted_gini = 0\n",
        "\n",
        "        for i in range(len(thresholds) + 1):\n",
        "            if i == 0:\n",
        "                indices = X[feature] <= thresholds[i]\n",
        "            elif i == len(thresholds):\n",
        "                indices = X[feature] > thresholds[i - 1]\n",
        "            else:\n",
        "                indices = (X[feature] > thresholds[i - 1]) & (X[feature] <= thresholds[i])\n",
        "\n",
        "            if len(y[indices]) == 0:\n",
        "                continue\n",
        "\n",
        "            split_gini = self._gini(y[indices])\n",
        "            weight = len(y[indices]) / len(y)\n",
        "            total_weighted_gini += weight * split_gini\n",
        "\n",
        "        return parent_gini - total_weighted_gini\n",
        "\n",
        "    def _gini(self, y):\n",
        "        proportions = y.value_counts(normalize=True)\n",
        "        return 1 - np.sum(proportions**2)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return X.apply(lambda row: self._predict_node(row, self.tree), axis=1)\n",
        "\n",
        "    def _predict_node(self, row, node):\n",
        "        if not isinstance(node, tuple):\n",
        "            return node\n",
        "\n",
        "        feature, thresholds, sub_trees = node\n",
        "        for i in range(len(thresholds)):\n",
        "            if row[feature] <= thresholds[i]:\n",
        "                return self._predict_node(row, sub_trees[i])\n",
        "        return self._predict_node(row, sub_trees[len(thresholds)])\n",
        "\n",
        "# Define the cross-validation function\n",
        "def cross_validate(X, y, k=10):\n",
        "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Initialize and train the decision tree\n",
        "        tree = DecisionTree(max_depth=8)\n",
        "        tree.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = tree.predict(X_test)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(accuracy)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "# Fetch the data\n",
        "wine_quality = fetch_ucirepo(id=186)\n",
        "X = wine_quality.data.features\n",
        "y = wine_quality.data.targets\n",
        "\n",
        "# Convert 'quality' to binary classification: 0 for < 7, 1 for >= 7\n",
        "y = (y['quality'] >= 7).astype(int)\n",
        "\n",
        "# Perform cross-validation\n",
        "average_accuracy = cross_validate(X, y, k=10)\n",
        "print(f\"Average Accuracy (10-fold CV): {average_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4_OUMhLqKaT",
        "outputId": "18935c7c-1b81-4d41-be4a-63a953a0c840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8307692307692308\n",
            "0.8430769230769231\n",
            "0.8523076923076923\n",
            "0.8184615384615385\n",
            "0.8476923076923077\n",
            "0.8353846153846154\n",
            "0.8184615384615385\n",
            "0.8459167950693375\n",
            "0.8551617873651772\n",
            "0.8536209553158706\n",
            "Average Accuracy (10-fold CV): 0.840\n"
          ]
        }
      ]
    }
  ]
}